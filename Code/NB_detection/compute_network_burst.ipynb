{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valebara/Alassio/blob/main/STH/compute_NB_STH_new_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!unzip -q Peak.zip"
      ],
      "metadata": {
        "id": "DrS-xbRxCUvU",
        "outputId": "2c6dc8f9-adb6-4d4e-dd2c-681d04c4b651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DrS-xbRxCUvU",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Peak_Trains/Prep2024_02_28/DIV21/BlExc/20575_Topo6/ptrain_21032024_10_01_nbasal_Joint/ptrain_21032024_10_01_nbasal/ptrain_21032024_10_01_nbasal_Joint_A02.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-05-24T08:36:03.670443800Z",
          "start_time": "2024-05-24T08:36:03.600269400Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "from scipy.signal import correlate, find_peaks, argrelmin\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def double_exp(x, a0, b0, a1, b1, d):\n",
        "    return a0 * (np.exp(b0 * x)) + a1 * (np.exp(b1 * x)) + d\n",
        "\n",
        "def single_exp(x, a, b, c):\n",
        "    return a*np.exp(-b*x) + c\n",
        "\n",
        "def gaussian_window(window_size, sigma):\n",
        "    x = np.linspace(-window_size // 2, window_size // 2, window_size)\n",
        "    gauss = np.exp(-0.5 * (x / sigma) ** 2)\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "def rect_window(window_size):\n",
        "    return np.ones(window_size) / window_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting spikes"
      ],
      "metadata": {
        "id": "Typv-2k0FSMW"
      },
      "id": "Typv-2k0FSMW"
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = \"Peak_Trains\"\n",
        "preps = os.listdir(output_folder)\n",
        "all_spikes = []\n",
        "IDs = []\n",
        "\n",
        "for prep in preps:\n",
        "    prep_path = os.path.join(output_folder, prep)\n",
        "    divs = os.listdir(prep_path)\n",
        "\n",
        "    for div in divs:\n",
        "        div_path = os.path.join(prep_path, div)\n",
        "        chem_blocks = os.listdir(div_path)\n",
        "\n",
        "        for chem_block in chem_blocks:\n",
        "            chem_block_path = os.path.join(div_path, chem_block)\n",
        "            mice = os.listdir(chem_block_path)\n",
        "\n",
        "            for mouse in mice:\n",
        "                mouse_path = os.path.join(chem_block_path, mouse)\n",
        "                phases = os.listdir(mouse_path)\n",
        "\n",
        "                for idx, phase in enumerate(phases):\n",
        "\n",
        "                    phase_path = os.path.join(mouse_path, phase)\n",
        "                    sub_phase_path = os.path.join(phase_path, os.listdir(phase_path)[0])\n",
        "\n",
        "                    phase_type = 'Basal' if 'basal' in phase else chem_block\n",
        "                    ID = prep+'_'+div+'_'+chem_block+'_'+mouse+'_'+phase_type\n",
        "                    IDs.append(ID)\n",
        "\n",
        "                    spikes = []\n",
        "\n",
        "                    for ptrain in sorted(os.listdir(sub_phase_path)):\n",
        "\n",
        "                        pt = loadmat(os.path.join(sub_phase_path, ptrain))['peak_train']\n",
        "                        spikes.append(pt.nonzero()[0])\n",
        "\n",
        "                    all_spikes.append(spikes)"
      ],
      "metadata": {
        "id": "VDjM2lvmCtS_"
      },
      "id": "VDjM2lvmCtS_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter setting"
      ],
      "metadata": {
        "id": "hfUG7AZ-aJ8P"
      },
      "id": "hfUG7AZ-aJ8P"
    },
    {
      "cell_type": "code",
      "source": [
        "numCh = 60\n",
        "freqSam = 10_000  # Hz\n",
        "freqSam_sub = 1_000  # Hz\n",
        "acqTime = 600  # s\n",
        "n_sam = int(freqSam_sub * acqTime)\n",
        "smooth_window = 100  # ms\n",
        "smooth_window = int(smooth_window * freqSam_sub / 1000)\n",
        "bin_el_att = 25  # ms\n",
        "bin_el_att = int(bin_el_att * freqSam_sub / 1000 /2)  # samples\n",
        "perc_min_peak_height = 0.1  # % (original 0.05)\n",
        "min_peak_distance = 800  # ms (original 800)\n",
        "min_peak_distance = int(min_peak_distance * freqSam_sub / 1000)  # samples\n",
        "nb_boundaries = 0.05  # 5 %\n",
        "pad_time = 4  # seconds\n",
        "pad_time = int(pad_time * freqSam_sub)\n",
        "transitory_period = 3  # minutes\n",
        "transitory_period = int(transitory_period  * freqSam_sub * 60)\n",
        "NBR_th = 1  # NBs/min\n",
        "\n",
        "max_isi_intra_burst = 60  # ms\n",
        "max_isi_intra_burst /= 1_000  # seconds\n",
        "min_num_spike_per_burst = 8\n",
        "min_num_elec_per_nb = 0.2*numCh\n",
        "min_height_ifr = min_num_spike_per_burst/((min_num_spike_per_burst-1)*max_isi_intra_burst)*min_num_elec_per_nb"
      ],
      "metadata": {
        "id": "M2i8llSHc7Ki"
      },
      "id": "M2i8llSHc7Ki",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Burst Detection + Spike Time Histogram"
      ],
      "metadata": {
        "collapsed": false,
        "id": "30f6ec3bf9aae0ad"
      },
      "id": "30f6ec3bf9aae0ad"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e9be30f6f18b>:91: RuntimeWarning:\n",
            "\n",
            "Mean of empty slice\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished iteration 1 - Prep2024_06_19_DIV21_BlExc_22642_Topo4_Basal\n"
          ]
        }
      ],
      "source": [
        "os.makedirs('NB', exist_ok=True)\n",
        "os.makedirs('STH', exist_ok=True)\n",
        "\n",
        "ID_targets = ['Prep2024_06_19_DIV21_BlExc_22642_Topo4_Basal',\n",
        "              'Prep2024_02_28_DIV21_BlExc_22647_Topo2_Basal',\n",
        "              'Prep2024_06_19_DIV21_BlInh_22645_Topo3_Basal']\n",
        "\n",
        "for idx_sth, (spikes, ID) in enumerate(zip(all_spikes, IDs)):\n",
        "\n",
        "    if ID != ID_targets[0]:\n",
        "        continue\n",
        "\n",
        "    ''' Network Burst Detection '''\n",
        "\n",
        "    spikes_sub = [np.round(sp/(freqSam/freqSam_sub)).astype(int) for sp in spikes]\n",
        "    spikes_conc = np.concatenate(spikes_sub)\n",
        "\n",
        "    if 'Basal' not in ID:\n",
        "        spikes_no_trans = spikes_conc[spikes_conc >= transitory_period]\n",
        "        rec_time = 7\n",
        "    else:\n",
        "        spikes_no_trans = spikes_conc\n",
        "        rec_time = acqTime/60\n",
        "\n",
        "    cum_spikes, sp_count = np.unique(spikes_no_trans, return_counts=True)\n",
        "    cum_peak = np.zeros(n_sam)\n",
        "    cum_peak[cum_spikes] = sp_count\n",
        "\n",
        "    cum_ifr = np.convolve(cum_peak, gaussian_window(smooth_window, smooth_window / 6)*freqSam_sub, mode='same')\n",
        "\n",
        "    peaks, _ = find_peaks(cum_ifr, height=max(min_height_ifr, perc_min_peak_height*np.amax(cum_ifr)), distance=min_peak_distance)\n",
        "\n",
        "    net_burst_start = np.zeros(len(peaks), dtype=int)\n",
        "    net_burst_end = np.zeros(len(peaks), dtype=int)\n",
        "\n",
        "    for idx, peak in enumerate(peaks):\n",
        "\n",
        "        pre_peak = peaks[idx - 1] if idx > 0 else max(0, peak - pad_time)\n",
        "        post_peak = peaks[idx + 1] if idx < len(peaks) - 1 else min(len(cum_ifr), peak + pad_time)\n",
        "\n",
        "        ifr_pre_peak = cum_ifr[pre_peak:peak][::-1]\n",
        "        ifr_post_peak = cum_ifr[peak:post_peak]\n",
        "\n",
        "        ifr_bound = max(nb_boundaries*cum_ifr[peak], min_height_ifr/2)\n",
        "\n",
        "        pre_indices = np.where(ifr_pre_peak <= ifr_bound)[0]\n",
        "        post_indices = np.where(ifr_post_peak <= ifr_bound)[0]\n",
        "\n",
        "        net_burst_start[idx] = peak - (pre_indices[0] if pre_indices.size > 0 else np.argmin(ifr_pre_peak))\n",
        "        net_burst_end[idx] = peak + (post_indices[0] if post_indices.size > 0 else np.argmin(ifr_post_peak))\n",
        "\n",
        "    assert len(peaks) == len(net_burst_start) == len(net_burst_end)\n",
        "\n",
        "    ''' Channel metrics '''\n",
        "\n",
        "    elecs_active = np.full((numCh, len(net_burst_start)), False)\n",
        "    net_burst_start_elec = np.full((numCh, len(net_burst_start)), np.nan)\n",
        "    net_burst_end_elec = np.full((numCh, len(net_burst_start)), np.nan)\n",
        "\n",
        "    for idx, (start, end) in enumerate(zip(net_burst_start, net_burst_end)):\n",
        "\n",
        "        elecs_active[:, idx] =  np.array([any((start <= sp) & (sp <= end)) for sp in spikes_sub])\n",
        "        net_burst_start_elec[:, idx] = np.array([sp[(start <= sp) & (sp <= end)][0] if len(sp[(start <= sp) & (sp <= end)]) else np.nan for sp in spikes_sub])\n",
        "        net_burst_end_elec[:, idx] = np.array([sp[(start <= sp) & (sp <= end)][-1] if len(sp[(start <= sp) & (sp <= end)]) else np.nan for sp in spikes_sub])\n",
        "\n",
        "    valid_nb = np.sum(elecs_active, axis=0) >= min_num_elec_per_nb\n",
        "\n",
        "    peaks = peaks[valid_nb]\n",
        "    net_burst_start = net_burst_start[valid_nb]\n",
        "    net_burst_end = net_burst_end[valid_nb]\n",
        "    net_burst_dur = net_burst_end - net_burst_start\n",
        "    elecs_active_per_burst = np.sum(elecs_active[:, valid_nb], axis=0)\n",
        "\n",
        "    net_burst_start_elec = net_burst_start_elec[:, valid_nb]\n",
        "    net_burst_end_elec = net_burst_end_elec[:, valid_nb]\n",
        "    net_burst_dur_elec = net_burst_end_elec - net_burst_start_elec\n",
        "    net_burst_dur_elec[net_burst_dur_elec==0] = np.nan  # single spikes within NBs -> set NB_duration to NaN\n",
        "    net_burst_participation_elec = np.sum(elecs_active[:, valid_nb], axis=1)\n",
        "\n",
        "    net_brust_rate = len(net_burst_start)/rec_time\n",
        "\n",
        "    if net_brust_rate >= NBR_th:\n",
        "        savemat(f'NB/nb_{ID}.mat', {'network_burst_rate': net_brust_rate,\n",
        "                                    'network_burst_start': net_burst_start,\n",
        "                                    'network_burst_end': net_burst_end,\n",
        "                                    'network_burst_duration': net_burst_dur,\n",
        "                                    'num_active_electrodes': elecs_active_per_burst,\n",
        "\n",
        "                                    'network_burst_start_elec': net_burst_start_elec,\n",
        "                                    'network_burst_end_elec': net_burst_end_elec,\n",
        "                                    'network_burst_duration_elec': np.nanmean(net_burst_dur_elec, axis=1).reshape(-1,1),\n",
        "                                    'num_nb_participation_elec': (100*net_burst_participation_elec/len(net_burst_start)).reshape(-1,1),\n",
        "                                    'network_burst_rate_elec': (net_burst_participation_elec/rec_time).reshape(-1,1)\n",
        "                                    })\n",
        "\n",
        "    else:\n",
        "        savemat(f'NB/nb_{ID}.mat', {'network_burst_rate': 0,\n",
        "                                    'network_burst_start': np.nan,\n",
        "                                    'network_burst_end': np.nan,\n",
        "                                    'network_burst_duration': np.nan,\n",
        "                                    'num_active_electrodes': np.nan,\n",
        "\n",
        "                                    'network_burst_start_elec': np.full((numCh,1), np.nan),\n",
        "                                    'network_burst_end_elec': np.full((numCh,1), np.nan),\n",
        "                                    'network_burst_duration_elec': np.full((numCh,1), np.nan),\n",
        "                                    'num_nb_participation_elec': np.full((numCh,1), np.nan),\n",
        "                                    'network_burst_rate_elec': np.zeros((numCh,1))\n",
        "                                    })\n",
        "\n",
        "        no_nb_log = f'No NB iteration {idx_sth} - {ID}'\n",
        "        print(\"\\033[1m\" + no_nb_log + \"\\033[0m\")\n",
        "        continue\n",
        "\n",
        "    ''' Spike Time Histogram '''\n",
        "\n",
        "    max_nbd = np.amax(net_burst_dur)\n",
        "    t_pre = 100  # ms (Savi: 500 ms)\n",
        "    t_pre = int(t_pre * freqSam_sub / 1000)\n",
        "    bursts_profile = np.zeros((len(net_burst_start), max_nbd+t_pre))\n",
        "\n",
        "    for idx, nb_start in enumerate(net_burst_start):\n",
        "        tmp = cum_ifr[np.clip(nb_start - t_pre, 0, None).astype(int):nb_start + max_nbd - 1]\n",
        "        if len(tmp) < max_nbd + t_pre:\n",
        "            tmp2 = np.concatenate((tmp, np.full(max_nbd + t_pre - len(tmp), tmp[-1])))\n",
        "        bursts_profile[idx, :] = tmp2\n",
        "\n",
        "    net_burst_profile_norm = bursts_profile/np.amax(bursts_profile)\n",
        "    R_idx = []\n",
        "\n",
        "    for idx_r, nb_ref in enumerate(net_burst_profile_norm):\n",
        "\n",
        "        R_after = []\n",
        "        shifted_burst_profile = np.zeros_like(bursts_profile)\n",
        "        shifted_burst_profile_norm = np.zeros_like(bursts_profile)\n",
        "\n",
        "        for idx, (norm_profile, profile) in enumerate(zip(net_burst_profile_norm, bursts_profile)):\n",
        "\n",
        "            shift = np.argmax(correlate(nb_ref, norm_profile))-len(nb_ref)+1\n",
        "\n",
        "            if shift > 0:  # reference starts after\n",
        "                shifted_burst_profile[idx, shift:] = profile[shift:]\n",
        "                shifted_burst_profile_norm[idx, shift:] = norm_profile[shift:]\n",
        "            else:\n",
        "                shifted_burst_profile[idx, :shift] = profile[:shift]\n",
        "                shifted_burst_profile_norm[idx, :shift] = norm_profile[:shift]\n",
        "\n",
        "            R_after.append(np.corrcoef(nb_ref, shifted_burst_profile_norm[idx, :])[0, 1])\n",
        "        R_idx.append(np.nanmean(R_after))\n",
        "\n",
        "    ref_idx = np.argmax(R_idx)\n",
        "    nb_ref = net_burst_profile_norm[ref_idx]\n",
        "\n",
        "    shifted_burst_profile = np.zeros_like(bursts_profile)\n",
        "    shifted_burst_profile_norm = np.zeros_like(bursts_profile)\n",
        "\n",
        "    for idx, (norm_profile, profile) in enumerate(zip(net_burst_profile_norm, bursts_profile)):\n",
        "\n",
        "        shift = np.argmax(correlate(nb_ref, norm_profile))-len(nb_ref)+1\n",
        "\n",
        "        if shift > 0:  # reference starts after\n",
        "            shifted_burst_profile[idx, shift:] = profile[shift:]\n",
        "            shifted_burst_profile_norm[idx, shift:] = norm_profile[shift:]\n",
        "        else:\n",
        "            shifted_burst_profile[idx, :shift] = profile[:shift]\n",
        "            shifted_burst_profile_norm[idx, :shift] = norm_profile[:shift]\n",
        "\n",
        "    sth = np.mean(shifted_burst_profile, axis=0)\n",
        "    np.save(f'STH/sth_{ID}.npy', sth)\n",
        "\n",
        "    print(f'Finished iteration {idx_sth} - {ID}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-24T08:36:30.761917700Z",
          "start_time": "2024-05-24T08:36:04.287830600Z"
        },
        "id": "3b37817cb8e74331",
        "outputId": "56e8ce19-329e-4596-ce16-8878b4d296cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3b37817cb8e74331",
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting STH"
      ],
      "metadata": {
        "id": "cSShRMW6Aj_E"
      },
      "id": "cSShRMW6Aj_E"
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('STH_fitting', exist_ok=True)\n",
        "os.makedirs('STH_plot', exist_ok=True)\n",
        "\n",
        "low_rise, low_decay = 0.1, 0.2\n",
        "high_rise, high_decay = 0.8, 0.8\n",
        "\n",
        "for idx_sth, sth_file in enumerate(os.listdir('STH')):\n",
        "\n",
        "    ID = sth_file[4:-4]\n",
        "    sth = np.load(os.path.join('STH', sth_file))\n",
        "\n",
        "    idx_peak = np.argmax(sth)\n",
        "    flag_rise = True\n",
        "    flag_decay = True\n",
        "\n",
        "    ''' Rise '''\n",
        "\n",
        "    start_rise = np.searchsorted(sth[:idx_peak], low_rise * sth[idx_peak], side='right')\n",
        "    end_rise = np.searchsorted(sth[:idx_peak], high_rise * sth[idx_peak], side='right')\n",
        "    sth_rise = sth[start_rise:end_rise]\n",
        "\n",
        "    bounds_rise = ((0, 1/freqSam_sub, 0, 1/freqSam_sub, 0), (1e7/freqSam_sub, 100/freqSam_sub, 1e7/freqSam_sub, 100/freqSam_sub, np.amax(sth)))\n",
        "    try:\n",
        "        param_rise, cov_rise = curve_fit(double_exp, np.arange(len(sth_rise)), sth_rise, bounds=bounds_rise, maxfev=100000)\n",
        "        slope_rise = min(param_rise[1], param_rise[3])\n",
        "        fitted_rise = double_exp(np.arange(len(sth_rise)), *param_rise)\n",
        "        r2_rise = r2_score(fitted_rise, sth_rise)\n",
        "    except:\n",
        "        print(f'Failed to fit rise: {ID}')\n",
        "        flag_rise = True\n",
        "\n",
        "    ''' Decay '''\n",
        "\n",
        "    sth_after_peak = sth[idx_peak:][::-1]\n",
        "    start_decay = len(sth_after_peak) - np.searchsorted(sth_after_peak, high_decay * sth[idx_peak], side='left') + idx_peak\n",
        "    end_decay = len(sth_after_peak) - np.searchsorted(sth_after_peak, low_decay * sth[idx_peak], side='left') + idx_peak -1\n",
        "    sth_decay = sth[start_decay:end_decay]\n",
        "\n",
        "    bounds_decay = ((0, 1/freqSam_sub, 0), (1e7/freqSam_sub, 100/freqSam_sub, np.amax(sth)))\n",
        "    try:\n",
        "        param_decay, cov_decay = curve_fit(single_exp, np.arange(len(sth_decay)), sth_decay, bounds=bounds_decay, maxfev=100000)\n",
        "        fitted_decay = single_exp(np.arange(len(sth_decay)), *param_decay)\n",
        "        r2_decay = r2_score(fitted_decay, sth_decay)\n",
        "        slope_decay = param_decay[1]\n",
        "    except:\n",
        "        print(f'Failed to fit decay: {ID}')\n",
        "        flag_decay = False\n",
        "\n",
        "    if flag_rise and flag_decay:\n",
        "        rounding = 3\n",
        "        df = pd.DataFrame({\"Rise\": [round(1/slope_rise, rounding), round(r2_rise, rounding)],\n",
        "                    \"Decay\": [round(1/slope_decay, rounding), round(r2_decay, rounding)]},\n",
        "                    index=['Slope (ms)', 'R2'])\n",
        "\n",
        "        savemat(f'STH_fitting/sth_fitting_{ID}.mat',{'df': df.to_dict(), 'sth': sth})\n",
        "\n",
        "    ''' Saving plot '''\n",
        "\n",
        "    markersize = 8\n",
        "    color_line = '#E0A824'\n",
        "    color_low_rise = '#D62F2F'\n",
        "    color_low_decay = '#EA4F27'\n",
        "    color_high = '#F57C2A'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4), layout='constrained')\n",
        "    time_axis = np.arange(len(sth)) * 1000 / freqSam_sub\n",
        "\n",
        "    ax.plot(time_axis, sth, linewidth=3, label='STH', zorder=1)\n",
        "\n",
        "    ax.scatter([start_rise * 1000 / freqSam_sub], [sth[start_rise]], color=color_low_rise, s=markersize**2, label=f'Low rise: {int(low_rise * 100)} %', zorder=2)\n",
        "    ax.scatter([end_rise * 1000 / freqSam_sub], [sth[end_rise]], color=color_high, s=markersize**2, label=f'High: {int(high_rise * 100)} %', zorder=2)\n",
        "    ax.scatter([start_decay * 1000 / freqSam_sub], [sth[start_decay]], color=color_high, s=markersize**2, zorder=2)\n",
        "    ax.scatter([end_decay * 1000 / freqSam_sub], [sth[end_decay]], color=color_low_decay, s=markersize**2, label=f'Low decay: {int(low_decay * 100)} %', zorder=2)\n",
        "\n",
        "    if flag_rise:\n",
        "        ax.plot(np.arange(start_rise, end_rise) * 1000 / freqSam_sub, fitted_rise, linestyle='-', linewidth=1.5, label='Fitting', color=color_line, zorder=2)\n",
        "    if flag_decay:\n",
        "        ax.plot(np.arange(start_decay, end_decay) * 1000 / freqSam_sub, fitted_decay, linestyle='-', linewidth=1.5, color=color_line, zorder=2)\n",
        "\n",
        "    if flag_rise and flag_decay:\n",
        "        table_data = [[f\"{df.loc['Slope (ms)', 'Rise']}\", f\"{df.loc['Slope (ms)', 'Decay']}\"],\n",
        "         [f\"{df.loc['R2', 'Rise']}\", f\"{df.loc['R2', 'Decay']}\"]]\n",
        "\n",
        "        ax.table(cellText=table_data,\n",
        "                colLabels=['Rise', 'Decay'],\n",
        "                rowLabels=['Slope (ms)', 'RÂ²'],\n",
        "                loc='upper right',\n",
        "                cellLoc='center',\n",
        "                bbox=[0.75, 0.75, 0.2, 0.15])\n",
        "\n",
        "    ax.set_xlabel('Time (ms)')\n",
        "    ax.set_ylabel('Spikes/s')\n",
        "    ax.set_title(f'STH - {ID}')\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "    save_fig = True\n",
        "    if save_fig:\n",
        "        fig.savefig(f'STH_plot/sth_plot_{ID}.png', dpi=300)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        ax.set_title(ID)\n",
        "        plt.show()\n",
        "\n",
        "    print(f'Finished iteration {idx_sth} - {ID}')"
      ],
      "metadata": {
        "id": "n_KU2gFqMMhk",
        "collapsed": true,
        "outputId": "c4bae859-a2ad-4a1d-f490-4953f85ef015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n_KU2gFqMMhk",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished iteration 0 - Prep2024_02_28_DIV21_BlExc_22647_Topo2_Basal\n",
            "Finished iteration 1 - Prep2024_06_19_DIV21_BlInh_22645_Topo3_Basal\n",
            "Finished iteration 2 - Prep2024_06_19_DIV21_BlExc_22642_Topo4_Basal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip all data to download\n",
        "\n"
      ],
      "metadata": {
        "id": "rJUAfOX-MYhi"
      },
      "id": "rJUAfOX-MYhi"
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r NB.zip NB\n",
        "# !zip -r STH.zip STH\n",
        "# !zip -r STH_fitting.zip STH_fitting\n",
        "# !zip -r STH_plot.zip STH_plot"
      ],
      "metadata": {
        "id": "75mdgiAiMa4S"
      },
      "id": "75mdgiAiMa4S",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check"
      ],
      "metadata": {
        "id": "WIPIoR20BcQ-"
      },
      "id": "WIPIoR20BcQ-"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# ''' Network Burst Detection '''\n",
        "\n",
        "# fig = go.Figure()\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(len(cum_ifr)) / freqSam_sub,\n",
        "#     y=cum_ifr,\n",
        "#     mode='lines',\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=peaks / freqSam_sub,\n",
        "#     y=cum_ifr[peaks],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color='red', size=8, symbol='x'),\n",
        "#     name='Peaks'\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=net_burst_start / freqSam_sub,\n",
        "#     y=cum_ifr[net_burst_start],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color='orange', size=8, symbol='x'),\n",
        "#     name='Burst Start'\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=net_burst_end / freqSam_sub,\n",
        "#     y=cum_ifr[net_burst_end],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color='yellow', size=8, symbol='x'),\n",
        "#     name='Burst End'\n",
        "# ))\n",
        "\n",
        "# fig.update_xaxes(title_text=\"seconds\")\n",
        "# fig.update_yaxes(title_text=\"spikes/s\")\n",
        "\n",
        "# fig.update_layout(\n",
        "#     title=f'Cumulative IFR - {ID}',\n",
        "#     xaxis_title='Seconds',\n",
        "#     yaxis_title='Spikes/s',\n",
        "# )\n",
        "\n",
        "# fig.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-24T08:36:33.449458200Z",
          "start_time": "2024-05-24T08:36:30.769739400Z"
        },
        "id": "1e5369dbca91affe"
      },
      "id": "1e5369dbca91affe",
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "# ''' Spike time Histogram '''\n",
        "\n",
        "# markersize = 10\n",
        "# color_line = '#E0A824'\n",
        "# color_low = '#D62F2F'\n",
        "# color_high = '#F57C2A'\n",
        "\n",
        "# fig = go.Figure()\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(len(sth)) * 1000 / freqSam_sub,\n",
        "#     y=sth,\n",
        "#     mode='lines',\n",
        "#     line=dict(width=3),\n",
        "#     showlegend=False\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(start_rise, end_rise) * 1000 / freqSam_sub,\n",
        "#     y=fitted_rise,\n",
        "#     mode='lines',\n",
        "#     line=dict(color=color_line, width=1.5),\n",
        "#     showlegend=False\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=[start_rise * 1000 / freqSam_sub],\n",
        "#     y=[sth[start_rise]],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color=color_low, size=markersize),\n",
        "#     name=f'Low: {int(low_rise * 100)} %'\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=[end_rise * 1000 / freqSam_sub],\n",
        "#     y=[sth[end_rise]],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color=color_high, size=markersize),\n",
        "#     name=f'High: {int(high_rise * 100)} %'\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(start_decay, end_decay) * 1000 / freqSam_sub,\n",
        "#     y=fitted_decay,\n",
        "#     mode='lines',\n",
        "#     line=dict(color=color_line, width=1.5),\n",
        "#     showlegend=False\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=[start_decay * 1000 / freqSam_sub],\n",
        "#     y=[sth[start_decay]],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color=color_high, size=markersize),\n",
        "#     showlegend=False\n",
        "# ))\n",
        "\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=[end_decay * 1000 / freqSam_sub],\n",
        "#     y=[sth[end_decay]],\n",
        "#     mode='markers',\n",
        "#     marker=dict(color=color_low, size=markersize),\n",
        "#     showlegend=False\n",
        "# ))\n",
        "\n",
        "# fig.update_layout(\n",
        "#     height=600,\n",
        "#     width=800,\n",
        "#     xaxis_title='ms',\n",
        "#     yaxis_title='spikes/s',\n",
        "#     title=f'STH - {ID}',\n",
        "#     showlegend=True\n",
        "# )\n",
        "\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "ZAHk1xOGOopb"
      },
      "id": "ZAHk1xOGOopb",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwABQng7JCY1"
      },
      "id": "iwABQng7JCY1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
